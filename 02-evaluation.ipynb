{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd37008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fcd46ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'results_50/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ec8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Load metrics\n",
    "with open('data/metrics_history_50.json', 'r') as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Epochs: {metrics['last_epoch'] + 1}\")\n",
    "print(f\"Metrics tracked: {len(metrics['train_loss'])} epochs\")\n",
    "print()\n",
    "\n",
    "# Best scores\n",
    "print(\"BEST SCORES:\")\n",
    "print(f\"  Lowest Train Loss: {min(metrics['train_loss']):.4f} (Epoch {np.argmin(metrics['train_loss'])})\")\n",
    "print(f\"  Lowest Val Loss:   {min(metrics['val_loss']):.4f} (Epoch {np.argmin(metrics['val_loss'])})\")\n",
    "print(f\"  Best BLEU-1:       {max(metrics['bleu1']):.4f} (Epoch {np.argmax(metrics['bleu1'])})\")\n",
    "print(f\"  Best BLEU-4:       {max(metrics['bleu4']):.4f} (Epoch {np.argmax(metrics['bleu4'])})\")\n",
    "print(f\"  Best METEOR:       {max(metrics['meteor']):.4f} (Epoch {np.argmax(metrics['meteor'])})\")\n",
    "print(f\"  Best ROUGE-L:      {max(metrics['rouge_l']):.4f} (Epoch {np.argmax(metrics['rouge_l'])})\")\n",
    "print()\n",
    "\n",
    "# Final scores\n",
    "print(\"FINAL SCORES:\")\n",
    "print(f\"  Train Loss:  {metrics['train_loss'][-1]:.4f}\")\n",
    "print(f\"  Val Loss:    {metrics['val_loss'][-1]:.4f}\")\n",
    "print(f\"  BLEU-1:      {metrics['bleu1'][-1]:.4f}\")\n",
    "print(f\"  BLEU-4:      {metrics['bleu4'][-1]:.4f}\")\n",
    "print(f\"  METEOR:      {metrics['meteor'][-1]:.4f}\")\n",
    "print(f\"  ROUGE-L:     {metrics['rouge_l'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a9e694",
   "metadata": {},
   "source": [
    "## Train and Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a798746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(len(metrics['train_loss']))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, metrics['train_loss'], label='Train Loss', marker='o', linewidth=2)\n",
    "plt.plot(epochs, metrics['val_loss'], label='Validation Loss', marker='s', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Training and Validation Loss Over Time', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, 'loss_curves.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73da5afc",
   "metadata": {},
   "source": [
    "### BLEU Score\n",
    "\n",
    "BLEU (Bilingual Evaluation Understudy) is a score used to evaluate the quality of machine-translated text by comparing it to human reference translations. The score ranges from 0 to 1, where 1 indicates a perfect match and 0 indicates no overlap. Higher scores generally mean better translations, with scores between 0.4 and 0.5 considered high quality. A good BLEU score depends on the specific task and data, but a score above 0.6 can be considered better than human-level in some contexts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0398b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(len(metrics['bleu1']))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, metrics['bleu1'], label='BLEU-1', marker='o', linewidth=2)\n",
    "plt.plot(epochs, metrics['bleu2'], label='BLEU-2', marker='s', linewidth=2)\n",
    "plt.plot(epochs, metrics['bleu3'], label='BLEU-3', marker='^', linewidth=2)\n",
    "plt.plot(epochs, metrics['bleu4'], label='BLEU-4', marker='d', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('BLEU Score', fontsize=12)\n",
    "plt.title('BLEU Scores Progression', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir,'bleu_scores.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76317016",
   "metadata": {},
   "source": [
    "### METEOR and ROUGE-L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b765536",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(len(metrics['meteor']))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, metrics['meteor'], label='METEOR', marker='o', linewidth=2, color='green')\n",
    "plt.plot(epochs, metrics['rouge_l'], label='ROUGE-L', marker='s', linewidth=2, color='red')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.title('METEOR and ROUGE-L Scores', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir,'meteor_rouge.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d06eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate gap between train and val loss\n",
    "loss_gap = [val - train for train, val in zip(metrics['train_loss'], metrics['val_loss'])]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, loss_gap, marker='o', linewidth=2, color='purple')\n",
    "plt.axhline(y=0, color='red', linestyle='--', label='No Gap')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Validation Loss - Train Loss', fontsize=12)\n",
    "plt.title('Train-Val Loss Gap (Overfitting Indicator)', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir,'overfitting_check.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ“ Saved: overfitting_check.png\")\n",
    "print()\n",
    "if loss_gap[-1] > 0.1:\n",
    "    print(\"Model may be overfitting (large train-val gap)\")\n",
    "elif loss_gap[-1] < 0:\n",
    "    print(\"Model is generalizing well\")\n",
    "else:\n",
    "    print(\"Minimal overfitting detect*ed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
